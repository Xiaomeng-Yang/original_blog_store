<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xun&#39;s Gallery</title>
  
  <subtitle>About everything interesting~</subtitle>
  <link href="https://rachel-yang.github.io/atom.xml" rel="self"/>
  
  <link href="https://rachel-yang.github.io/"/>
  <updated>2022-12-05T07:23:31.979Z</updated>
  <id>https://rachel-yang.github.io/</id>
  
  <author>
    <name>珣XUN</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[ICPR-2022] Portmanteauing Features for Scene Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/12/04/Portmanteauing-Features-for-Scene-Text-Recognition/"/>
    <id>https://rachel-yang.github.io/2022/12/04/Portmanteauing-Features-for-Scene-Text-Recognition/</id>
    <published>2022-12-04T06:24:20.000Z</published>
    <updated>2022-12-05T07:23:31.979Z</updated>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Paper: &lt;a href=&quot;https://arxiv.org/pdf/2211.05036.pdf&quot;&gt;https://arxiv.org/pdf/2211.05036.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: Waiting…; &lt;a href=&quot;https://github.com/chewyukai/portmanteauing-features&quot;&gt;https://github.com/chewyukai/portmanteauing-features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tips: Portmanteau features, which utilizes both the original and rectified images; Rectification network,&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Rectification Network" scheme="https://rachel-yang.github.io/tags/Rectification-Network/"/>
    
  </entry>
  
  <entry>
    <title>IterVM: Iterative Vision Modeling Module for Scene Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/12/03/IterVM-Iterative-Vision-Modeling-Module-for-Scene-Text-Recognition/"/>
    <id>https://rachel-yang.github.io/2022/12/03/IterVM-Iterative-Vision-Modeling-Module-for-Scene-Text-Recognition/</id>
    <published>2022-12-03T07:28:03.000Z</published>
    <updated>2022-12-04T06:24:36.703Z</updated>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Paper: &lt;a href=&quot;https://arxiv.org/abs/2204.02630&quot;&gt;https://arxiv.org/abs/2204.02630&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a href=&quot;https://github.com/VDIGPKU/IterNet&quot;&gt;https://github.com/VDIGPKU/IterNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tips: IterVM + IterLM, &lt;strong&gt;iterative vision module&lt;/strong&gt;, introduce &lt;font color=&quot;#32adff&quot;&gt;feedback connections from the output into the middle layers&lt;/font&gt; of vision modeling module.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Vision Module" scheme="https://rachel-yang.github.io/tags/Vision-Module/"/>
    
  </entry>
  
  <entry>
    <title>[2022-ECCV] Levenshtein OCR</title>
    <link href="https://rachel-yang.github.io/2022/11/29/Levenshtein-OCR/"/>
    <id>https://rachel-yang.github.io/2022/11/29/Levenshtein-OCR/</id>
    <published>2022-11-29T07:27:51.000Z</published>
    <updated>2022-12-03T07:29:54.059Z</updated>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Paper: &lt;a href=&quot;https://arxiv.org/abs/2209.03594v1&quot;&gt;https://arxiv.org/abs/2209.03594v1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: Waiting…&lt;/li&gt;
&lt;li&gt;Tips: Iterative refinement, interpretability (whether to depend on the linguistic information or not)&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/11/29/Levenshtein-OCR/overview.jpg&quot; width=&quot;600&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>[2022-TIP] PETR: Rethinking the Capability of Transformer-Based Language Model in Scene Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/10/12/PETR-Model/"/>
    <id>https://rachel-yang.github.io/2022/10/12/PETR-Model/</id>
    <published>2022-10-12T06:39:49.000Z</published>
    <updated>2022-12-03T07:30:45.530Z</updated>
    
    
    <summary type="html">&lt;p&gt;This paper utilizes &lt;font color=&quot;#32adff&quot;&gt;destructed scene text images and predicted length loss&lt;/font&gt;. They destruct the images, and design a module to classify whether the input image is destructed or not. Besides, the loss of the predicted label’s length is used to optimize the model. &lt;/p&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>[2022-ECCV] Scene Text Recognition with Single-Point Decoding Network</title>
    <link href="https://rachel-yang.github.io/2022/10/12/Scene-Text-Recognition-with-Single-Point-Decoding-Network/"/>
    <id>https://rachel-yang.github.io/2022/10/12/Scene-Text-Recognition-with-Single-Point-Decoding-Network/</id>
    <published>2022-10-12T06:39:49.000Z</published>
    <updated>2022-10-16T12:31:36.350Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h1 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h1&gt;&lt;h1 id=&quot;Method&quot;&gt;&lt;a</summary>
        
      
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] Scene Text Recognition with Permuted Autoregressive Sequence Models</title>
    <link href="https://rachel-yang.github.io/2022/09/13/Parseq-Model/"/>
    <id>https://rachel-yang.github.io/2022/09/13/Parseq-Model/</id>
    <published>2022-09-13T13:00:11.000Z</published>
    <updated>2022-09-16T12:05:23.671Z</updated>
    
    
    <summary type="html">&lt;p&gt;This method utilize the idea of XLNet (Permuted language Model), which is an outstanding work in the area of NLP.&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>STR Papers List</title>
    <link href="https://rachel-yang.github.io/2022/07/11/STR-papers-list/"/>
    <id>https://rachel-yang.github.io/2022/07/11/STR-papers-list/</id>
    <published>2022-07-11T10:04:40.000Z</published>
    <updated>2022-11-29T12:34:44.580Z</updated>
    
    
    <summary type="html">&lt;p&gt;This post lists papers about scene text recognition published in top conferences.&lt;/p&gt;
&lt;h1 id=&quot;Latest-Papers-updated-on-11-20&quot;&gt;&lt;a href=&quot;#Latest-Papers-updated-on-11-20&quot; class=&quot;headerlink&quot; title=&quot;Latest Papers (updated on 11.20)&quot;&gt;&lt;/a&gt;Latest Papers (updated on 11.20)&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Arxiv: [IterVM: Iterative Vision Modeling Module for Scene Text Recognition]&lt;/li&gt;
&lt;li&gt;Applied intelligence: [Scene text recognition based on two-stage attention and multi-branch feature fusion module]&lt;/li&gt;
&lt;li&gt;ICPR-2022: [Portmanteauing Features for Scene Text Recognition]&lt;/li&gt;
&lt;li&gt;TMM-2022: [Dual Relation Network for Scene Text Recognition]&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Scene Text Recognition" scheme="https://rachel-yang.github.io/categories/Scene-Text-Recognition/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining</title>
    <link href="https://rachel-yang.github.io/2022/07/11/Mask-OCR/"/>
    <id>https://rachel-yang.github.io/2022/07/11/Mask-OCR/</id>
    <published>2022-07-11T09:58:07.000Z</published>
    <updated>2022-07-13T11:06:14.089Z</updated>
    
    
    <summary type="html">&lt;p&gt;This paper explores the way to employ &lt;font color=&quot;#32adff&quot;&gt;MAE’s idea&lt;/font&gt; in STR task. It pretrains the STR encoder in a self-supervised manner (formed with N transformer encoder) over unlabeled real text images, while pretraining decoder on synthesized text images using the supervision loss.&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="MAE" scheme="https://rachel-yang.github.io/tags/MAE/"/>
    
    <category term="Self-supervised" scheme="https://rachel-yang.github.io/tags/Self-supervised/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] Joint Visual Semantic Reasoning: Multi-Stage Decoder for Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/06/25/Joint-Visual-Semantic-Reasoning/"/>
    <id>https://rachel-yang.github.io/2022/06/25/Joint-Visual-Semantic-Reasoning/</id>
    <published>2022-06-25T07:21:27.000Z</published>
    <updated>2022-06-30T10:01:12.922Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h1&gt;&lt;p&gt;How to develop a visual-semantic reasoning skill for text recognition?&lt;/p&gt;
&lt;h1 id=&quot;Method&quot;&gt;&lt;a href=&quot;#Method&quot; class=&quot;headerlink&quot; title=&quot;Method&quot;&gt;&lt;/a&gt;Method&lt;/h1&gt;&lt;p&gt;The framework contains a &lt;font color=&quot;#32adff&quot;&gt;visual feature extractor&lt;/font&gt; extracts context-rich holistic feature and multi-scale feature maps, and a &lt;font color=&quot;#32adff&quot;&gt;multi-stage attentional decoder&lt;/font&gt; builds up the character sequence estimates.&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>DAN Model</title>
    <link href="https://rachel-yang.github.io/2022/06/24/DAN-Model/"/>
    <id>https://rachel-yang.github.io/2022/06/24/DAN-Model/</id>
    <published>2022-06-23T19:55:45.000Z</published>
    <updated>2022-06-23T19:55:45.751Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>[Paper Review] From Two to One: A New Scene Text Recognizer with Visual Language Modeling Network</title>
    <link href="https://rachel-yang.github.io/2022/06/24/From-two-to-one/"/>
    <id>https://rachel-yang.github.io/2022/06/24/From-two-to-one/</id>
    <published>2022-06-23T19:54:49.000Z</published>
    <updated>2022-10-12T06:45:17.455Z</updated>
    
    
    <summary type="html">&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/06/24/From-two-to-one/background.jpg&quot; width=&quot;400&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semi-Supervised" scheme="https://rachel-yang.github.io/tags/Semi-Supervised/"/>
    
    <category term="Mask" scheme="https://rachel-yang.github.io/tags/Mask/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] Multi-modal Text Recognition Networks: Interactive Enhancements between Visual and Semantic Features</title>
    <link href="https://rachel-yang.github.io/2022/06/24/MATRN-Model/"/>
    <id>https://rachel-yang.github.io/2022/06/24/MATRN-Model/</id>
    <published>2022-06-23T19:54:37.000Z</published>
    <updated>2022-07-07T09:51:58.647Z</updated>
    
    
    <summary type="html">&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/06/24/MATRN-Model/MATRN_pipeline.jpg&quot; width=&quot;750&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/06/23/ABINet-Model/"/>
    <id>https://rachel-yang.github.io/2022/06/23/ABINet-Model/</id>
    <published>2022-06-23T11:21:43.000Z</published>
    <updated>2022-07-11T10:00:24.765Z</updated>
    
    
    <summary type="html">&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/06/23/ABINet-Model/pipeline.jpg&quot; width=&quot;700&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
    <category term="Parallel Decoder" scheme="https://rachel-yang.github.io/tags/Parallel-Decoder/"/>
    
    <category term="Iterative Correction" scheme="https://rachel-yang.github.io/tags/Iterative-Correction/"/>
    
    <category term="Semi-supervised" scheme="https://rachel-yang.github.io/tags/Semi-supervised/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] Towards Accurate Scene Text Recognition with Semantic Reasoning Networks</title>
    <link href="https://rachel-yang.github.io/2022/06/23/Towards-Accurate-Scene-Text-Recognition-with-Semantic-Reasoning-Networks/"/>
    <id>https://rachel-yang.github.io/2022/06/23/Towards-Accurate-Scene-Text-Recognition-with-Semantic-Reasoning-Networks/</id>
    <published>2022-06-23T08:53:46.000Z</published>
    <updated>2022-06-27T07:48:32.861Z</updated>
    
    
    <summary type="html">&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/06/23/Towards-Accurate-Scene-Text-Recognition-with-Semantic-Reasoning-Networks/SRN_pipeline.jpg&quot; width=&quot;750&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
    <category term="Parallel Decoder" scheme="https://rachel-yang.github.io/tags/Parallel-Decoder/"/>
    
  </entry>
  
  <entry>
    <title>Review the Scene Text Recognition Models with Semantic Information</title>
    <link href="https://rachel-yang.github.io/2022/06/23/Review-the-Scene-Text-Recognition-Models-with-Semantic-Information/"/>
    <id>https://rachel-yang.github.io/2022/06/23/Review-the-Scene-Text-Recognition-Models-with-Semantic-Information/</id>
    <published>2022-06-23T05:18:59.000Z</published>
    <updated>2022-10-12T06:08:47.654Z</updated>
    
    
    <summary type="html">&lt;p&gt;This article reviews the ways that scene text recognition models utilize the semantic information to boost their performance, from the &lt;font color=&quot;#32adff&quot;&gt;Bahdanau Attention Decoder&lt;/font&gt; to various &lt;font color=&quot;#32adff&quot;&gt;Semantic Modules&lt;/font&gt;.&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Scene Text Recognition" scheme="https://rachel-yang.github.io/categories/Scene-Text-Recognition/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Review" scheme="https://rachel-yang.github.io/tags/Review/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] SEED: Semantics Enhanced Encoder-Decoder Framework for Scene Text Recognition</title>
    <link href="https://rachel-yang.github.io/2022/03/25/SEED-Model/"/>
    <id>https://rachel-yang.github.io/2022/03/25/SEED-Model/</id>
    <published>2022-03-25T06:52:20.000Z</published>
    <updated>2022-06-25T06:57:39.968Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2022/03/25/SEED-Model/pipeline.jpg&quot; width=&quot;750&quot;&gt;&lt;/div&gt;&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="STR" scheme="https://rachel-yang.github.io/tags/STR/"/>
    
    <category term="Semantic Module" scheme="https://rachel-yang.github.io/tags/Semantic-Module/"/>
    
  </entry>
  
  <entry>
    <title>Attention &amp; Transformer</title>
    <link href="https://rachel-yang.github.io/2022/01/23/Attention-Transformer/"/>
    <id>https://rachel-yang.github.io/2022/01/23/Attention-Transformer/</id>
    <published>2022-01-23T09:36:46.000Z</published>
    <updated>2022-06-25T06:56:05.016Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Attention&quot;&gt;&lt;a href=&quot;#Attention&quot; class=&quot;headerlink&quot; title=&quot;Attention&quot;&gt;&lt;/a&gt;Attention&lt;/h1&gt;&lt;p&gt;Attention mechanism mimics the retrieval of a value $v_i$ for a query $q$ based on a key $k_i$ in database.&lt;/p&gt;</summary>
    
    
    
    <category term="Basic Neural Networks" scheme="https://rachel-yang.github.io/categories/Basic-Neural-Networks/"/>
    
    
    <category term="attention" scheme="https://rachel-yang.github.io/tags/attention/"/>
    
    <category term="transformer" scheme="https://rachel-yang.github.io/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis</title>
    <link href="https://rachel-yang.github.io/2021/09/10/Algorithm-Design-and-Analysis/"/>
    <id>https://rachel-yang.github.io/2021/09/10/Algorithm-Design-and-Analysis/</id>
    <published>2021-09-10T01:44:12.000Z</published>
    <updated>2022-06-23T05:17:57.574Z</updated>
    
    
    <summary type="html">&lt;p&gt;Practical Problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;step1: topic choosing&lt;br&gt;A practical problem&lt;/li&gt;
&lt;li&gt;step 2: formulate the problem&lt;/li&gt;&lt;/ul&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Connectionist Temporal Classification with Maximum Entropy Regularization</title>
    <link href="https://rachel-yang.github.io/2021/08/05/Connectionist-Temporal-Classification-with-Maximum-Entropy-Regularization/"/>
    <id>https://rachel-yang.github.io/2021/08/05/Connectionist-Temporal-Classification-with-Maximum-Entropy-Regularization/</id>
    <published>2021-08-05T09:18:34.000Z</published>
    <updated>2022-06-23T05:16:51.922Z</updated>
    
    
    <summary type="html">&lt;h1 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h1&gt;&lt;p&gt;CTC tends to produce &lt;font color=&quot;32adff&quot;&gt;highly peaky and overconfident distributions&lt;/font&gt;, which is a symptom of &lt;strong&gt;overfitting&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Harm the training process: CTC lacks exploration and is prone to fall into worse local minima.&lt;/li&gt;
&lt;li&gt;Output overconfident paths: CTC tends to concentrate all its output distribution over one specific path.&lt;/li&gt;
&lt;li&gt;Output paths with peaky distribution.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="CTC" scheme="https://rachel-yang.github.io/tags/CTC/"/>
    
  </entry>
  
  <entry>
    <title>[Paper-Review] Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning</title>
    <link href="https://rachel-yang.github.io/2021/08/03/Virtual-Adversarial-Training-A-Regularization-Method-for-Supervised-and-Semi-Supervised-Learning/"/>
    <id>https://rachel-yang.github.io/2021/08/03/Virtual-Adversarial-Training-A-Regularization-Method-for-Supervised-and-Semi-Supervised-Learning/</id>
    <published>2021-08-03T09:45:12.000Z</published>
    <updated>2021-08-05T09:23:27.034Z</updated>
    
    
    <summary type="html">&lt;div align=&quot;center&quot;&gt; &lt;img src=&quot;/2021/08/03/Virtual-Adversarial-Training-A-Regularization-Method-for-Supervised-and-Semi-Supervised-Learning/authors.jpg&quot; width=&quot;700&quot;&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Paper Review" scheme="https://rachel-yang.github.io/categories/Paper-Review/"/>
    
    
    <category term="Adversarial Training" scheme="https://rachel-yang.github.io/tags/Adversarial-Training/"/>
    
    <category term="Improve Generalization" scheme="https://rachel-yang.github.io/tags/Improve-Generalization/"/>
    
    <category term="Semi-Supervised Learning" scheme="https://rachel-yang.github.io/tags/Semi-Supervised-Learning/"/>
    
  </entry>
  
</feed>
